{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Convolution2D, BatchNormalization, Flatten,\n",
    "                                     Dropout, Dense, AveragePooling2D, Add)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"./open/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"./npy_data/train_x_mfcc_stand.npy\", allow_pickle=True)\n",
    "train_y = np.load(\"./npy_data/train_y_mfcc_stand.npy\", allow_pickle=True)\n",
    "test_x = np.load(\"./npy_data/test_x_mfcc_stand.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.expand_dims(train_x, axis=-1)\n",
    "test_x = np.expand_dims(test_x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25520, 40, 501, 1), (25520,), (6100, 40, 501, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(input_, units = 32, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def second_block(input_, units = 64, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn():\n",
    "    dropout_rate = 0.3\n",
    "    \n",
    "    in_ = Input(shape = (train_x.shape[1:]))\n",
    "    \n",
    "    block_01 = block(in_, units = 32, dropout_rate = dropout_rate)\n",
    "    block_02 = block(block_01, units = 64, dropout_rate = dropout_rate)\n",
    "    block_03 = block(block_02, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    block_04 = second_block(block_03, units = 64, dropout_rate = dropout_rate)\n",
    "    block_05 = second_block(block_04, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    x = Flatten()(block_05)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_res, x])\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    model_out = Dense(units = 6, activation = 'softmax')(x)\n",
    "    model = Model(in_, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "638/638 [==============================] - 111s 129ms/step - loss: 1.8484 - acc: 0.3462 - val_loss: 1.3853 - val_acc: 0.3918\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.3415 - acc: 0.4380 - val_loss: 1.3685 - val_acc: 0.4522\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.2837 - acc: 0.4865 - val_loss: 1.3897 - val_acc: 0.5067\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.2053 - acc: 0.5449 - val_loss: 2.7359 - val_acc: 0.3918\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.1275 - acc: 0.5812 - val_loss: 4.9069 - val_acc: 0.3918\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 76s 118ms/step - loss: 1.0654 - acc: 0.6143 - val_loss: 2.8546 - val_acc: 0.3918\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.0271 - acc: 0.6267 - val_loss: 1.4142 - val_acc: 0.5717\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 0.9658 - acc: 0.6510 - val_loss: 1.6261 - val_acc: 0.4038\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 78s 117ms/step - loss: 1.8708 - acc: 0.3459 - val_loss: 1.4706 - val_acc: 0.3958\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.3462 - acc: 0.4386 - val_loss: 1.6081 - val_acc: 0.4038\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.3014 - acc: 0.4641 - val_loss: 3.8049 - val_acc: 0.3926\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.2623 - acc: 0.4944 - val_loss: 1.6663 - val_acc: 0.3928\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.2111 - acc: 0.5360 - val_loss: 10.7155 - val_acc: 0.3172\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.1319 - acc: 0.5870 - val_loss: 7.1404 - val_acc: 0.0980\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 74s 117ms/step - loss: 1.0816 - acc: 0.6041 - val_loss: 7.1379 - val_acc: 0.3926\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.0197 - acc: 0.6266 - val_loss: 4.2471 - val_acc: 0.3938\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 80s 119ms/step - loss: 1.7786 - acc: 0.3501 - val_loss: 4.0504 - val_acc: 0.3196\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.3401 - acc: 0.4519 - val_loss: 3.5018 - val_acc: 0.3918\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.3084 - acc: 0.5011 - val_loss: 1.3116 - val_acc: 0.5061\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.2295 - acc: 0.5509 - val_loss: 1.8280 - val_acc: 0.4022\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.1896 - acc: 0.5585 - val_loss: 7.0016 - val_acc: 0.3918\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 74s 115ms/step - loss: 1.1363 - acc: 0.5884 - val_loss: 1.6453 - val_acc: 0.3913\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.0957 - acc: 0.6033 - val_loss: 3.2762 - val_acc: 0.3918\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.0526 - acc: 0.6160 - val_loss: 2.3717 - val_acc: 0.2461\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 78s 118ms/step - loss: 1.8760 - acc: 0.3497 - val_loss: 1.4469 - val_acc: 0.3918\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.3655 - acc: 0.4355 - val_loss: 715.0380 - val_acc: 0.3918\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.3372 - acc: 0.4552 - val_loss: 1.6853 - val_acc: 0.3920\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.3399 - acc: 0.4404 - val_loss: 1.6485 - val_acc: 0.3918\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 72s 113ms/step - loss: 1.2967 - acc: 0.4790 - val_loss: 1.8652 - val_acc: 0.3922\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 71s 112ms/step - loss: 1.2337 - acc: 0.5320 - val_loss: 2.8468 - val_acc: 0.3930\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 71s 111ms/step - loss: 1.1645 - acc: 0.5702 - val_loss: 7.9477 - val_acc: 0.0982\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 82s 128ms/step - loss: 1.1176 - acc: 0.5901 - val_loss: 4.5898 - val_acc: 0.3918\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 85s 128ms/step - loss: 1.8442 - acc: 0.3538 - val_loss: 1.3660 - val_acc: 0.4034\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 79s 124ms/step - loss: 1.3350 - acc: 0.4421 - val_loss: 2.1005 - val_acc: 0.3987\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 80s 126ms/step - loss: 1.2665 - acc: 0.4831 - val_loss: 1.6419 - val_acc: 0.3887\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 82s 128ms/step - loss: 1.1919 - acc: 0.5542 - val_loss: 1.6055 - val_acc: 0.3774\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 79s 123ms/step - loss: 1.1102 - acc: 0.5933 - val_loss: 3.1815 - val_acc: 0.0592\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 81s 127ms/step - loss: 1.0505 - acc: 0.6144 - val_loss: 7.3825 - val_acc: 0.3918\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 81s 127ms/step - loss: 1.0072 - acc: 0.6271 - val_loss: 2.3832 - val_acc: 0.3864\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 81s 126ms/step - loss: 0.9803 - acc: 0.6398 - val_loss: 3.0295 - val_acc: 0.3642\n",
      "*******************************************************************\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "\n",
    "pred = []\n",
    "pred_ = []\n",
    "\n",
    "for train_idx, val_idx in split.split(train_x, train_y):\n",
    "    x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "    x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "\n",
    "    model = build_fn()\n",
    "    model.compile(optimizer = keras.optimizers.Adam(0.002),\n",
    "                 loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 metrics = ['acc'])\n",
    "\n",
    "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = 8)\n",
    "    print(\"*******************************************************************\")\n",
    "    pred.append(model.predict(test_x))\n",
    "    pred_.append(np.argmax(model.predict(test_x), axis = 1))\n",
    "    print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./open/test\\1.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./open/test\\10.wav</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./open/test\\100.wav</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./open/test\\1000.wav</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./open/test\\1001.wav</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   path    id\n",
       "0     ./open/test\\1.wav     1\n",
       "1    ./open/test\\10.wav    10\n",
       "2   ./open/test\\100.wav   100\n",
       "3  ./open/test\\1000.wav  1000\n",
       "4  ./open/test\\1001.wav  1001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_ 데이터 프레임을 만들어서 나중에 sample_submission과 id를 기준으로 merge시킬 준비를 합니다.\n",
    "\n",
    "def get_id(data):\n",
    "    return np.int(data.split(\"\\\\\")[1].split(\".\")[0])\n",
    "\n",
    "test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n",
    "test_[\"path\"] = glob(\"./open/test/*.wav\")\n",
    "test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n",
    "\n",
    "test_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_type(data):\n",
    "    return np.int(data)\n",
    "\n",
    "# 처음에 살펴본 것처럼 glob로 test data의 path는 sample_submission의 id와 같이 1,2,3,4,5.....으로 정렬 되어있지 않습니다.\n",
    "# 만들어둔 test_ 데이터프레임을 이용하여 sample_submission과 predict값의 id를 맞춰줍니다.\n",
    "\n",
    "result = pd.concat([test_, pd.DataFrame(np.mean(pred, axis = 0))], axis = 1).iloc[:, 1:]\n",
    "result[\"id\"] = result[\"id\"].apply(lambda x : cov_type(x))\n",
    "\n",
    "result = pd.merge(sample_submission[\"id\"], result)\n",
    "result.columns = sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.316642</td>\n",
       "      <td>0.021924</td>\n",
       "      <td>0.616556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.053273</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.334029</td>\n",
       "      <td>0.013907</td>\n",
       "      <td>0.590627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.381097</td>\n",
       "      <td>0.068654</td>\n",
       "      <td>0.515618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.221082</td>\n",
       "      <td>0.168760</td>\n",
       "      <td>0.524233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.165240</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.036891</td>\n",
       "      <td>0.033748</td>\n",
       "      <td>0.759937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.328067</td>\n",
       "      <td>0.023923</td>\n",
       "      <td>0.572155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.197408</td>\n",
       "      <td>0.023794</td>\n",
       "      <td>0.757605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.380186</td>\n",
       "      <td>0.096070</td>\n",
       "      <td>0.507788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.025076</td>\n",
       "      <td>0.323675</td>\n",
       "      <td>0.113335</td>\n",
       "      <td>0.509443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.395308</td>\n",
       "      <td>0.065745</td>\n",
       "      <td>0.525647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    africa  australia    canada   england  hongkong        us\n",
       "0        1  0.021453   0.011284  0.012142  0.316642  0.021924  0.616556\n",
       "1        2  0.053273   0.004386  0.003779  0.334029  0.013907  0.590627\n",
       "2        3  0.023268   0.006103  0.005260  0.381097  0.068654  0.515618\n",
       "3        4  0.077639   0.004357  0.003929  0.221082  0.168760  0.524233\n",
       "4        5  0.165240   0.002309  0.001874  0.036891  0.033748  0.759937\n",
       "...    ...       ...        ...       ...       ...       ...       ...\n",
       "6095  6096  0.007139   0.031349  0.037368  0.328067  0.023923  0.572155\n",
       "6096  6097  0.012792   0.004143  0.004257  0.197408  0.023794  0.757605\n",
       "6097  6098  0.011950   0.001996  0.002011  0.380186  0.096070  0.507788\n",
       "6098  6099  0.010967   0.017504  0.025076  0.323675  0.113335  0.509443\n",
       "6099  6100  0.009313   0.002043  0.001943  0.395308  0.065745  0.525647\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result/03_MFCC_stand.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN3",
   "language": "python",
   "name": "gan3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
