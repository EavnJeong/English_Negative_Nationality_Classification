{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Convolution2D, BatchNormalization, Flatten,\n",
    "                                     Dropout, Dense, AveragePooling2D, Add)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"./open/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"./npy_data/train_x_mfcc.npy\", allow_pickle=True)\n",
    "train_y = np.load(\"./npy_data/train_y_mfcc.npy\", allow_pickle=True)\n",
    "test_x = np.load(\"./npy_data/test_x_mfcc.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25520, 40, 501, 1), (25520,), (6100, 40, 501, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(input_, units = 32, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def second_block(input_, units = 64, dropout_rate = 0.5):\n",
    "    \n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn():\n",
    "    dropout_rate = 0.3\n",
    "    \n",
    "    in_ = Input(shape = (train_x.shape[1:]))\n",
    "    \n",
    "    block_01 = block(in_, units = 32, dropout_rate = dropout_rate)\n",
    "    block_02 = block(block_01, units = 64, dropout_rate = dropout_rate)\n",
    "    block_03 = block(block_02, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    block_04 = second_block(block_03, units = 64, dropout_rate = dropout_rate)\n",
    "    block_05 = second_block(block_04, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    x = Flatten()(block_05)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_res, x])\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    model_out = Dense(units = 6, activation = 'softmax')(x)\n",
    "    model = Model(in_, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "638/638 [==============================] - 119s 131ms/step - loss: 1.8269 - acc: 0.3477 - val_loss: 1.4279 - val_acc: 0.4534\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 77s 121ms/step - loss: 1.2945 - acc: 0.4845 - val_loss: 1.2536 - val_acc: 0.5302\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 72s 112ms/step - loss: 1.2068 - acc: 0.5429 - val_loss: 1.2422 - val_acc: 0.5529\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 70s 110ms/step - loss: 1.0999 - acc: 0.5906 - val_loss: 1.8364 - val_acc: 0.4146\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.0417 - acc: 0.6186 - val_loss: 1.1981 - val_acc: 0.5886\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 0.9798 - acc: 0.6392 - val_loss: 2.2213 - val_acc: 0.2968\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 0.9289 - acc: 0.6613 - val_loss: 2.0782 - val_acc: 0.3329\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 0.8831 - acc: 0.6717 - val_loss: 1.4322 - val_acc: 0.5684\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 76s 114ms/step - loss: 1.8718 - acc: 0.3461 - val_loss: 1.4661 - val_acc: 0.3918\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 72s 113ms/step - loss: 1.3374 - acc: 0.4485 - val_loss: 1.4543 - val_acc: 0.4161\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 72s 113ms/step - loss: 1.2820 - acc: 0.4884 - val_loss: 1.3170 - val_acc: 0.5041\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 72s 112ms/step - loss: 1.2257 - acc: 0.5377 - val_loss: 1.6534 - val_acc: 0.3209\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.1688 - acc: 0.5754 - val_loss: 1.1457 - val_acc: 0.5989\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 72s 113ms/step - loss: 1.0874 - acc: 0.5988 - val_loss: 1.0808 - val_acc: 0.5978\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 72s 113ms/step - loss: 1.0299 - acc: 0.6219 - val_loss: 1.2614 - val_acc: 0.5325\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 72s 114ms/step - loss: 0.9717 - acc: 0.6432 - val_loss: 1.4937 - val_acc: 0.4694\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 78s 116ms/step - loss: 1.8187 - acc: 0.3630 - val_loss: 1.3273 - val_acc: 0.4207\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.3443 - acc: 0.4402 - val_loss: 1.3594 - val_acc: 0.4528\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 74s 115ms/step - loss: 1.2790 - acc: 0.4757 - val_loss: 1.2866 - val_acc: 0.4826\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 81s 128ms/step - loss: 1.2312 - acc: 0.5159 - val_loss: 2.3430 - val_acc: 0.4148\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 76s 119ms/step - loss: 1.1468 - acc: 0.5698 - val_loss: 1.1575 - val_acc: 0.5735\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.0627 - acc: 0.6070 - val_loss: 2.5923 - val_acc: 0.2725\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.0327 - acc: 0.6223 - val_loss: 1.7103 - val_acc: 0.4636\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 74s 117ms/step - loss: 0.9803 - acc: 0.6353 - val_loss: 1.2982 - val_acc: 0.5586\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 82s 121ms/step - loss: 1.8559 - acc: 0.3581 - val_loss: 1.5419 - val_acc: 0.4183\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 81s 127ms/step - loss: 1.3264 - acc: 0.4522 - val_loss: 1.4415 - val_acc: 0.4534\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 78s 123ms/step - loss: 1.2704 - acc: 0.4876 - val_loss: 1.3886 - val_acc: 0.4346\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 79s 124ms/step - loss: 1.2057 - acc: 0.5341 - val_loss: 1.1686 - val_acc: 0.5652\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 74s 116ms/step - loss: 1.1334 - acc: 0.5819 - val_loss: 1.4258 - val_acc: 0.4416\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 75s 118ms/step - loss: 1.0780 - acc: 0.6090 - val_loss: 1.1975 - val_acc: 0.5298\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 1.0359 - acc: 0.6222 - val_loss: 1.5207 - val_acc: 0.4606\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 74s 115ms/step - loss: 0.9780 - acc: 0.6369 - val_loss: 1.2848 - val_acc: 0.5255\n",
      "*******************************************************************\n",
      "*******************************************************************\n",
      "Epoch 1/8\n",
      "638/638 [==============================] - 78s 117ms/step - loss: 1.8736 - acc: 0.3448 - val_loss: 1.3853 - val_acc: 0.4071\n",
      "Epoch 2/8\n",
      "638/638 [==============================] - 72s 114ms/step - loss: 1.3342 - acc: 0.4437 - val_loss: 2.1350 - val_acc: 0.3656\n",
      "Epoch 3/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.2822 - acc: 0.4962 - val_loss: 1.7987 - val_acc: 0.3979\n",
      "Epoch 4/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.2095 - acc: 0.5354 - val_loss: 1.5100 - val_acc: 0.4755\n",
      "Epoch 5/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.1232 - acc: 0.5861 - val_loss: 1.3415 - val_acc: 0.5631\n",
      "Epoch 6/8\n",
      "638/638 [==============================] - 73s 114ms/step - loss: 1.0577 - acc: 0.6102 - val_loss: 1.1921 - val_acc: 0.6003\n",
      "Epoch 7/8\n",
      "638/638 [==============================] - 72s 114ms/step - loss: 1.0214 - acc: 0.6325 - val_loss: 1.3565 - val_acc: 0.5529\n",
      "Epoch 8/8\n",
      "638/638 [==============================] - 73s 115ms/step - loss: 0.9892 - acc: 0.6334 - val_loss: 1.5816 - val_acc: 0.4042\n",
      "*******************************************************************\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "\n",
    "pred = []\n",
    "pred_ = []\n",
    "\n",
    "for train_idx, val_idx in split.split(train_x, train_y):\n",
    "    x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "    x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "\n",
    "    model = build_fn()\n",
    "    model.compile(optimizer = keras.optimizers.Adam(0.002),\n",
    "                 loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "                 metrics = ['acc'])\n",
    "\n",
    "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = 8)\n",
    "    print(\"*******************************************************************\")\n",
    "    pred.append(model.predict(test_x))\n",
    "    pred_.append(np.argmax(model.predict(test_x), axis = 1))\n",
    "    print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./open/test\\1.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./open/test\\10.wav</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./open/test\\100.wav</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./open/test\\1000.wav</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./open/test\\1001.wav</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   path    id\n",
       "0     ./open/test\\1.wav     1\n",
       "1    ./open/test\\10.wav    10\n",
       "2   ./open/test\\100.wav   100\n",
       "3  ./open/test\\1000.wav  1000\n",
       "4  ./open/test\\1001.wav  1001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_ 데이터 프레임을 만들어서 나중에 sample_submission과 id를 기준으로 merge시킬 준비를 합니다.\n",
    "\n",
    "def get_id(data):\n",
    "    return np.int(data.split(\"\\\\\")[1].split(\".\")[0])\n",
    "\n",
    "test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n",
    "test_[\"path\"] = glob(\"./open/test/*.wav\")\n",
    "test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n",
    "\n",
    "test_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_type(data):\n",
    "    return np.int(data)\n",
    "\n",
    "# 처음에 살펴본 것처럼 glob로 test data의 path는 sample_submission의 id와 같이 1,2,3,4,5.....으로 정렬 되어있지 않습니다.\n",
    "# 만들어둔 test_ 데이터프레임을 이용하여 sample_submission과 predict값의 id를 맞춰줍니다.\n",
    "\n",
    "result = pd.concat([test_, pd.DataFrame(np.mean(pred, axis = 0))], axis = 1).iloc[:, 1:]\n",
    "result[\"id\"] = result[\"id\"].apply(lambda x : cov_type(x))\n",
    "\n",
    "result = pd.merge(sample_submission[\"id\"], result)\n",
    "result.columns = sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.231429</td>\n",
       "      <td>0.166547</td>\n",
       "      <td>0.147352</td>\n",
       "      <td>0.166429</td>\n",
       "      <td>0.205743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.136189</td>\n",
       "      <td>0.024284</td>\n",
       "      <td>0.026924</td>\n",
       "      <td>0.540895</td>\n",
       "      <td>0.044115</td>\n",
       "      <td>0.227593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.171692</td>\n",
       "      <td>0.022535</td>\n",
       "      <td>0.024520</td>\n",
       "      <td>0.540868</td>\n",
       "      <td>0.045691</td>\n",
       "      <td>0.194694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.130227</td>\n",
       "      <td>0.025831</td>\n",
       "      <td>0.022820</td>\n",
       "      <td>0.431846</td>\n",
       "      <td>0.159374</td>\n",
       "      <td>0.229903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.118807</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.137190</td>\n",
       "      <td>0.107941</td>\n",
       "      <td>0.607555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.138235</td>\n",
       "      <td>0.104961</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.286812</td>\n",
       "      <td>0.287371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.025658</td>\n",
       "      <td>0.178435</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.766120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0.107931</td>\n",
       "      <td>0.022889</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>0.524090</td>\n",
       "      <td>0.050649</td>\n",
       "      <td>0.271504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0.047528</td>\n",
       "      <td>0.069540</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.299448</td>\n",
       "      <td>0.209472</td>\n",
       "      <td>0.302712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0.103069</td>\n",
       "      <td>0.013686</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.485415</td>\n",
       "      <td>0.177816</td>\n",
       "      <td>0.207056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    africa  australia    canada   england  hongkong        us\n",
       "0        1  0.082500   0.231429  0.166547  0.147352  0.166429  0.205743\n",
       "1        2  0.136189   0.024284  0.026924  0.540895  0.044115  0.227593\n",
       "2        3  0.171692   0.022535  0.024520  0.540868  0.045691  0.194694\n",
       "3        4  0.130227   0.025831  0.022820  0.431846  0.159374  0.229903\n",
       "4        5  0.118807   0.014341  0.014166  0.137190  0.107941  0.607555\n",
       "...    ...       ...        ...       ...       ...       ...       ...\n",
       "6095  6096  0.035955   0.138235  0.104961  0.146667  0.286812  0.287371\n",
       "6096  6097  0.012191   0.014799  0.025658  0.178435  0.002796  0.766120\n",
       "6097  6098  0.107931   0.022889  0.022937  0.524090  0.050649  0.271504\n",
       "6098  6099  0.047528   0.069540  0.071300  0.299448  0.209472  0.302712\n",
       "6099  6100  0.103069   0.013686  0.012958  0.485415  0.177816  0.207056\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result/03_MFCC.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAN3",
   "language": "python",
   "name": "gan3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
